{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Interviews\\\\eClerx\\\\twcs\\\\twcs.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing null values with -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1000, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"created_at\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the parent tweet/message i.e. those messages which have no in_response_to_tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMainTweets = df[df[\"in_response_to_tweet_id\"] == -1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280576, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMainTweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the relationship of tweet id and in_response_to_tweet_id, filtering the inbound = True messages so that a user's entire tweet is in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstTweetContent = []\n",
    "\n",
    "\n",
    "cnt = 1\n",
    "for x in dfMainTweets.values:\n",
    "    \n",
    "    tweet_id = x[0]\n",
    "    content = x[3]\n",
    "    boolInbound = False\n",
    "    \n",
    "    print(cnt)\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    while(1==1):\n",
    "        dfTemp = df[df[\"in_response_to_tweet_id\"] == tweet_id]\n",
    "        \n",
    "        if len(dfTemp) ==0:\n",
    "            break\n",
    "        \n",
    "        boolInbound = dfTemp[\"inbound\"].values[0]\n",
    "        \n",
    "        if boolInbound == True:\n",
    "            content = content + \" \" + dfTemp[\"text\"].values[0]\n",
    "            boolInbound = False\n",
    "        \n",
    "        tweet_id = dfTemp[\"tweet_id\"].values[0]\n",
    "            \n",
    "        \n",
    "    lstTweetContent.append(content)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The merged tweets was stored in a local path and is used for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfMergedTweets = pd.DataFrame({\"text\" : lstTweetContent})\n",
    "dfMergedTweets = pd.read_csv(\"D:\\\\Interviews\\\\eClerx\\\\Output\\\\merged_tweets.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sprintcare is the worst customer service @spr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@115714 yÃ¢ÂÂall lie about your Ã¢ÂÂgreatÃ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actually that's a broken link you sent me and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo @Ask_Spectrum, your customer service reps a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @sprintcare is the worst customer service @spr...\n",
       "1  @115714 yÃ¢ÂÂall lie about your Ã¢ÂÂgreatÃ...\n",
       "2  @115714 whenever I contact customer support, t...\n",
       "3  actually that's a broken link you sent me and ...\n",
       "4  Yo @Ask_Spectrum, your customer service reps a..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMergedTweets = dfMergedTweets[[\"text\"]]\n",
    "dfMergedTweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the @username from each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMergedTweets[\"text\"] = [\" \".join(filter(lambda x:x[0]!='@', str(a).split())) for a in dfMergedTweets[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the unicode characters with their english counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMergedTweets[\"text\"] = [(x.encode('ascii', 'ignore')).decode(\"utf-8\") for x in dfMergedTweets[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is the worst customer service I did. I have se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yall lie about your great connection. 5 bars L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whenever I contact customer support, they tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actually that's a broken link you sent me and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo your customer service reps are super nice b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280662</th>\n",
       "      <td>Hi, How can I get back to IOS10 in my iPhone 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280663</th>\n",
       "      <td>Hey #Apple thanks for not warning me that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280664</th>\n",
       "      <td>I need help with my iCloud Photo Library Why d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280665</th>\n",
       "      <td>When does you good  https://t.co/6IEZZBMhmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280666</th>\n",
       "      <td>watford, bought crayfish tails the other day. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280667 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       is the worst customer service I did. I have se...\n",
       "1       yall lie about your great connection. 5 bars L...\n",
       "2       whenever I contact customer support, they tell...\n",
       "3       actually that's a broken link you sent me and ...\n",
       "4       Yo your customer service reps are super nice b...\n",
       "...                                                   ...\n",
       "280662  Hi, How can I get back to IOS10 in my iPhone 6...\n",
       "280663  Hey #Apple thanks for not warning me that the ...\n",
       "280664  I need help with my iCloud Photo Library Why d...\n",
       "280665        When does you good  https://t.co/6IEZZBMhmn\n",
       "280666  watford, bought crayfish tails the other day. ...\n",
       "\n",
       "[280667 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMergedTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.9, min_df=2, stop_words=\"english\")\n",
    "dtm = cv.fit_transform(dfMergedTweets[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA with 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components= 10, random_state = 42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the most frequent words in the 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 words for Topic 0\n",
      "['people', 'dm', 'customers', 'amp', 'don', 'worst', 'like', 'im', 'time', 'guys', 'phone', 'just', 'https', 'customer', 'service']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 1\n",
      "['fargo', 'wells', 'lo', 'para', 'ya', 'da', 'se', 'por', 'es', 'mi', 'https', 'en', 'la', 'el', 'que']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 2\n",
      "['https', 'euston', 'just', 'ticket', 'trains', 'going', 'today', 'staff', 'time', 'internet', 'london', 'customer', 'thanks', 'train', 'service']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 3\n",
      "['ne', 'il', 'ai', 'vous', 'mon', 'pour', 'en', 'que', 'et', 'la', 'pas', 'est', 'je', 'le', 'https']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 4\n",
      "['phone', 'app', 'dm', 'sent', 'trying', 'just', 'https', 'thanks', 'number', 'need', 'email', 'hi', 'card', 'help', 'account']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 5\n",
      "['minutes', 'waiting', 'just', 'ordered', 'prime', 'time', 'days', 'https', 'today', 'package', 'delivered', 'day', 'amazon', 'delivery', 'order']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 6\n",
      "['working', 'watch', 'tv', 'apple', 'fix', 'internet', 'just', 'https', 'new', 'ios', 'app', '11', 'update', 'iphone', 'phone']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 7\n",
      "['today', 'want', 'food', 'christmas', 'really', 'good', 'got', 'thank', 'amp', 'love', 'store', 'like', 'thanks', 'just', 'https']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 8\n",
      "['seat', 'flying', 'plane', 'ride', 'flights', 'trip', 'time', 'uber', 'thank', 'amp', 'just', 'driver', 'thanks', 'https', 'flight']\n",
      "\n",
      "\n",
      "Top 15 words for Topic 9\n",
      "['tried', 'problem', 'thanks', 'getting', 'spotify', 'music', 'app', 'just', 'play', 'fix', 'error', 'xbox', 'game', 'help', 'https']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(LDA.components_):\n",
    "    print(f\"Top 15 words for Topic {i}\")\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-15:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following are the topics which the tweets can be clustered/grouped into:\n",
    "\n",
    "1. Customer service calls\n",
    "2. Train ticketing queries\n",
    "3. Amazon delivery queries\n",
    "4. Apple products service requests\n",
    "5. Christmas food ordering\n",
    "6. Flight related queries\n",
    "7. Spotify/XBox issues and services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
